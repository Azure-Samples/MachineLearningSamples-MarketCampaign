{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Sentiment Classification Notebook\n",
    "\n",
    "\n",
    "## Summary\n",
    "Text Classification aims to assign a text instance into one or more class(es) in a predefined set of classes.\n",
    "\n",
    "## Description \n",
    "### Use Case Description\n",
    "A company, such as bank, wants to analyze customer feedback in order to provide additional insight to enhance market campaign prediction. The bank collects customers feedback from public website. The task is to build a pipeline that automatically analyzes customer feedback messages, to provide the overall sentiment for the bank. The aim is to help the bank who wants to more accurately predict the success of telemarketing calls for selling bank long-term deposits gain extra features from social media.\n",
    "\n",
    "#### Use Case Data\n",
    "The data used in this use case is [BankReview dataset](https://www.creditkarma.com/reviews/banking/single/id/Simple#single-review-listingPaper), a publicly available data set collected from credit karma website. The data comprises approximately 120 customers feedback. \n",
    "\n",
    "We shared the review data as a Blob in a public Windows Azure Storage account. You can use this shared data to follow the steps in this template, or you can collect more feedbacks from credit karma website.\n",
    "\n",
    "Each instance in the data set has 2 fields:\n",
    " \n",
    "* sentiment - the polarity of the feedback (1 = strongly negative, 2 = negative, 3 = neutral, 4 = positive, 5 = strongly positive)\n",
    "* review - the text of the feedback \n",
    "\n",
    "### Review Sentiment Operationalization\n",
    "\n",
    "### Schema Generatation\n",
    "In order to deploy the model as a web-service, we need first define functions to generate schema file for the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script generates the scoring and schema files\n",
    "# necessary to operationalize the Market Campaign prediction sample\n",
    "# Init and run functions\n",
    "\n",
    "from azureml.api.schema.dataTypes import DataTypes\n",
    "from azureml.api.schema.sampleDefinition import SampleDefinition\n",
    "from azureml.api.realtime.services import generate_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the web service definition by authoring\n",
    "# init() and run() functions. Test the fucntions\n",
    "# before deploying the web service.\n",
    "\n",
    "def init():\n",
    "    from sklearn.externals import joblib\n",
    "\n",
    "    # load the model file\n",
    "    global model\n",
    "    model = joblib.load('./code/reviewsentiment/model_30.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executed\n"
     ]
    }
   ],
   "source": [
    "def run(input_df):\n",
    "    import json\n",
    "    \n",
    "    input_df.columns = ['input_column'] \n",
    "    \n",
    "    stop_words_df = pd.read_csv('./data/StopWords.csv')\n",
    "    stop_words = set(stop_words_df[\"Col1\"].tolist())\n",
    "    for item in string.ascii_lowercase: #load stop words\n",
    "        if item != \"i\":\n",
    "            stop_words.add(item)\n",
    "\n",
    "    input_column = []\n",
    "    for line in input_df.input_column:\n",
    "        value = \" \".join(item.lower()\n",
    "                         for item in RegexpTokenizer(r'\\w+').tokenize(line)\n",
    "                         if item.lower() not in stop_words)\n",
    "        input_column.append(value)\n",
    "    input_df.input_column = input_column\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    input_list = input_df[\"input_column\"].tolist()\n",
    "\n",
    "    # Tokenize the sentences in text_list and remove morphological affixes from words.\n",
    "\n",
    "    def stem_tokens(tokens, stemmer_model):\n",
    "        '''\n",
    "        :param tokens: tokenized word list\n",
    "        :param stemmer: remove stemmer\n",
    "        :return:  tokenized and stemmed words\n",
    "        '''\n",
    "        return [stemmer_model.stem(original_word) for original_word in tokens]\n",
    "\n",
    "    def tokenize(text):\n",
    "        '''\n",
    "        :param text: raw test\n",
    "        :return: tokenized and stemmed words\n",
    "        '''\n",
    "        tokens = text.strip().split(\" \")\n",
    "        return stem_tokens(tokens, stemmer)\n",
    "\n",
    "    # Initialize the TfidfVectorizer to compute tf-idf for each word\n",
    "\n",
    "    tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english', max_df=160000,\n",
    "                            min_df=1, norm=\"l2\", use_idf=True)\n",
    "    tfs = tfidf.fit_transform(input_list)\n",
    "    \n",
    "    pred = model.predict(tfs[0, :30])\n",
    "    return json.dumps(str(pred[0]))\n",
    "    #return pred[0]\n",
    "print('executed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I absolutely love my bank. There's a reason th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  I absolutely love my bank. There's a reason th..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=[[\"I absolutely love my bank. There's a reason this bank's customer base is so strong--their customer service actually acts like people and not robots. I love that anytime my card is swiped, I'm instantly notified. And the built in budgeting app is something that really makes life easier. The biggest setback is not being able to deposit cash (you have to get a money order), and if you have another, non-simple bank account, transferring money between accounts can take a few days, which frankly isn't acceptable with most ACH taking a business day or less. Overall, it's a great bank, and I would recommend it to anyone.\"]], columns=['review'])\n",
    "df.dtypes\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I absolutely love my bank. There's a reason th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  I absolutely love my bank. There's a reason th..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init()\n",
    "input1 = pd.DataFrame(data=[[\"I absolutely love my bank. There's a reason this bank's customer base is so strong--their customer service actually acts like people and not robots. I love that anytime my card is swiped, I'm instantly notified. And the built in budgeting app is something that really makes life easier. The biggest setback is not being able to deposit cash (you have to get a money order), and if you have another, non-simple bank account, transferring money between accounts can take a few days, which frankly isn't acceptable with most ACH taking a business day or less. Overall, it's a great bank, and I would recommend it to anyone.\"]], columns=['review'])\n",
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"0\"'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': {'input_df': {'internal': 'gANjYXp1cmVtbC5hcGkuc2NoZW1hLnBhbmRhc1V0aWwKUGFuZGFzU2NoZW1hCnEAKYFxAX1xAihYDAAAAGNvbHVtbl90eXBlc3EDXXEEY251bXB5CmR0eXBlCnEFWAIAAABPOHEGSwBLAYdxB1JxCChLA1gBAAAAfHEJTk5OSv////9K/////0s/dHEKYmFYCgAAAHNjaGVtYV9tYXBxC31xDFgGAAAAcmV2aWV3cQ1oCHNYDAAAAGNvbHVtbl9uYW1lc3EOXXEPaA1hWAUAAABzaGFwZXEQSwFLAYZxEXViLg==',\n",
       "   'swagger': {'example': [{'review': \"I absolutely love my bank. There's a reason this bank's customer base is so strong--their customer service actually acts like people and not robots. I love that anytime my card is swiped, I'm instantly notified. And the built in budgeting app is something that really makes life easier. The biggest setback is not being able to deposit cash (you have to get a money order), and if you have another, non-simple bank account, transferring money between accounts can take a few days, which frankly isn't acceptable with most ACH taking a business day or less. Overall, it's a great bank, and I would recommend it to anyone.\"}],\n",
       "    'items': {'properties': {'review': {'type': 'string'}}, 'type': 'object'},\n",
       "    'type': 'array'},\n",
       "   'type': 3}}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"input_df\": SampleDefinition(DataTypes.PANDAS, df)}\n",
    "\n",
    "# The prepare statement writes the scoring file (main.py) and\n",
    "# the schema file (senti_service_schema.json) the the output folder.\n",
    "\n",
    "generate_schema(run_func=run, inputs=inputs, filepath='senti_service_schema.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Function\n",
    "Then, we will need to define a scoring function to score on the new instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    import numpy\n",
    "    import scipy\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    global model\n",
    "    import pickle\n",
    "    f = open('./code/reviewsentiment/model_30.pkl', 'rb')\n",
    "    model = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executed\n"
     ]
    }
   ],
   "source": [
    "# run takes an input dataframe and performs sentiment prediction\n",
    "def run(input_df):\n",
    "    import json\n",
    "    import pickle\n",
    "    \n",
    "    input_df.columns = ['input_column'] \n",
    "    \n",
    "    f = open('./code/reviewsentiment/stopwords.pkl', 'rb')\n",
    "    stop_words_df = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    stop_words = set(stop_words_df[\"Col1\"].tolist())\n",
    "    for item in string.ascii_lowercase: #load stop words\n",
    "        if item != \"i\":\n",
    "            stop_words.add(item)\n",
    "\n",
    "    input_column = []\n",
    "    for line in input_df.input_column:\n",
    "        value = \" \".join(item.lower()\n",
    "                         for item in RegexpTokenizer(r'\\w+').tokenize(line)\n",
    "                         if item.lower() not in stop_words)\n",
    "        input_column.append(value)\n",
    "    input_df.input_column = input_column\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    input_list = input_df[\"input_column\"].tolist()\n",
    "\n",
    "    # Tokenize the sentences in text_list and remove morphological affixes from words.\n",
    "\n",
    "    def stem_tokens(tokens, stemmer_model):\n",
    "        '''\n",
    "        :param tokens: tokenized word list\n",
    "        :param stemmer: remove stemmer\n",
    "        :return:  tokenized and stemmed words\n",
    "        '''\n",
    "        return [stemmer_model.stem(original_word) for original_word in tokens]\n",
    "\n",
    "    def tokenize(text):\n",
    "        '''\n",
    "        :param text: raw test\n",
    "        :return: tokenized and stemmed words\n",
    "        '''\n",
    "        tokens = text.strip().split(\" \")\n",
    "        return stem_tokens(tokens, stemmer)\n",
    "\n",
    "    # Initialize the TfidfVectorizer to compute tf-idf for each word\n",
    "\n",
    "    tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english', max_df=160000,\n",
    "                            min_df=1, norm=\"l2\", use_idf=True)\n",
    "    tfs = tfidf.fit_transform(input_list)\n",
    "    \n",
    "    pred = model.predict(tfs[0, :30])\n",
    "    return json.dumps(str(pred[0]))\n",
    "    #return pred[0]\n",
    "print('executed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"0\"\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    init()\n",
    "    input = pd.DataFrame(data=[[\"I absolutely love my bank. There's a reason this bank's customer base is so strong--their customer service actually acts like people and not robots. I love that anytime my card is swiped, I'm instantly notified. And the built in budgeting app is something that really  makes life easier. The biggest setback is not being able to deposit cash (you have to get a money order), and if you have another, non-simple bank account, transferring money between accounts can take a few days, which frankly isn't acceptable with most ACH taking a business day or less. Overall, it's a great bank, and I would recommend it to anyone.\"]], columns=['review'])\n",
    "    print(run(input))\n",
    "    #input = \"{}\"\n",
    "    #run(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
